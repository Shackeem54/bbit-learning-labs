{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXMOy+eQ09HOndkPpKKCrq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shackeem54/bbit-learning-labs/blob/main/Bank_%2CCustomers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# QUESTION 1: Decision Tree & Random Forest Classification\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (a) LOAD DATA\n",
        "# -------------------------------------------------------------\n",
        "df = pd.read_csv(\"Customer.csv\")\n",
        "\n",
        "feature_cols = [\n",
        "    \"Gender\",\"Married\",\"Education\",\"ApplicantIncome\",\"CoapplicantIncome\",\n",
        "    \"LoanAmount\",\"Loan_Amount_Term\",\"Credit_History\",\"Property_Area\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"Loan_Status\"].copy()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (b) LABEL ENCODING & FEATURE SCALING\n",
        "# -------------------------------------------------------------\n",
        "label_cols = [\"Gender\", \"Married\", \"Education\", \"Property_Area\", \"Loan_Status\"]\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "X = df[feature_cols].copy()\n",
        "y = df[\"Loan_Status\"].copy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "num_cols = [\"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", \"Loan_Amount_Term\"]\n",
        "\n",
        "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (c) TRAIN-TEST SPLIT & CLASSIFICATION\n",
        "# -------------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (d) GENERATE & SAVE TREE IMAGES\n",
        "# -------------------------------------------------------------\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(dt, feature_names=feature_cols, filled=True, fontsize=8)\n",
        "plt.title(\"Decision Tree Classifier\")\n",
        "plt.savefig(\"DecisionTree.png\", dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# FIRST TWO AND LAST TWO TREES FROM RANDOM FOREST\n",
        "trees_to_show = [0, 1, -2, -1]\n",
        "\n",
        "for i, t in enumerate(trees_to_show):\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plot_tree(rf.estimators_[t], feature_names=feature_cols, filled=True, fontsize=8)\n",
        "    plt.title(f\"Random Forest Tree #{t+1}\")\n",
        "    plt.savefig(f\"RF_Tree_{t+1}.png\", dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (e) CROSS-VALIDATION ACCURACIES & CONFUSION MATRICES\n",
        "# -------------------------------------------------------------\n",
        "dt_cv = cross_val_score(dt, X, y, cv=5)\n",
        "rf_cv = cross_val_score(rf, X, y, cv=5)\n",
        "\n",
        "print(\"Decision Tree 5-Fold Accuracy:\", dt_cv.mean())\n",
        "print(\"Random Forest 5-Fold Accuracy:\", rf_cv.mean())\n",
        "\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "print(\"\\nDecision Tree Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"\\nRandom Forest Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (f) FEATURE IMPORTANCE (RANDOM FOREST)\n",
        "# -------------------------------------------------------------\n",
        "importances = rf.feature_importances_\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=importances, y=feature_cols, palette=\"viridis\")\n",
        "plt.title(\"Feature Importance - Random Forest\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dcDvVunbByM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------\n",
        "# QUESTION 2: Clustering\n",
        "# -------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# LOAD DATA\n",
        "# -------------------------------------------------------------\n",
        "housing = pd.read_csv(\"Housing.csv\")\n",
        "\n",
        "features = [\"price\", \"area\", \"stories\", \"basement\", \"parking\"]\n",
        "X = housing[features].copy()\n",
        "\n",
        "# SCALE FEATURES\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (a) DEFAULT K-MEANS\n",
        "# -------------------------------------------------------------\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X_scaled)\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (b) FIRST 100 CLUSTER MEMBERSHIPS & CENTROIDS\n",
        "# -------------------------------------------------------------\n",
        "print(\"Cluster Membership of First 100 samples:\")\n",
        "print(labels[:100])\n",
        "\n",
        "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "print(\"\\nCluster Centers (denormalized):\")\n",
        "print(pd.DataFrame(centroids, columns=features))\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (c) ELBOW METHOD\n",
        "# -------------------------------------------------------------\n",
        "inertia_vals = []\n",
        "cluster_sizes = [5, 10, 15, 20, 25, 30]\n",
        "\n",
        "for k in cluster_sizes:\n",
        "    km = KMeans(n_clusters=k, random_state=42)\n",
        "    km.fit(X_scaled)\n",
        "    inertia_vals.append(km.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(cluster_sizes, inertia_vals, marker='o')\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (d) SCATTER PLOT (PRICE vs AREA)\n",
        "# -------------------------------------------------------------\n",
        "# Choose best k from elbow (example: 10)\n",
        "k_opt = 10\n",
        "kmeans_final = KMeans(n_clusters=k_opt, random_state=42)\n",
        "labels_final = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(housing[\"price\"], housing[\"area\"], c=labels_final, cmap=\"tab20\")\n",
        "plt.xlabel(\"Price\")\n",
        "plt.ylabel(\"Area\")\n",
        "plt.title(f\"K-Means Clusters (k={k_opt})\")\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# (e) AGGLOMERATIVE CLUSTERING + DENDROGRAM\n",
        "# -------------------------------------------------------------\n",
        "X2 = housing[[\"price\", \"area\"]].copy()\n",
        "X2_scaled = StandardScaler().fit_transform(X2)\n",
        "\n",
        "linked = linkage(X2_scaled, method=\"ward\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "dendrogram(linked, truncate_mode=\"level\", p=6)\n",
        "plt.title(\"Agglomerative Clustering Dendrogram\")\n",
        "plt.xlabel(\"Sample Index\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()\n",
        "\n",
        "agg = AgglomerativeClustering(n_clusters=3, linkage=\"ward\")\n",
        "labels_agg = agg.fit_predict(X2_scaled)\n"
      ],
      "metadata": {
        "id": "l8RRYp6eB7Cu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}